{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Netflix Retention Case Study\n**Author:** Deni Kurti  \n**Created:** 2025-08-28\n\n---\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Introduction & Questions\n- What are the retention patterns by first-watch month (cohorts)?\n- Which genres/categories drive engagement over time?\n- Are there differences by country/region (top 10)?\n- Simple churn baseline: who is likely to stop watching next month?\n\n> Fill this with a short business goal + dataset description.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Data Loading & Schema Check\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\npd.set_option(\"display.max_columns\", 50)\n\nraw_path = \"data/raw/netflix_titles.csv\"  # TODO: replace/confirm\ndf = pd.read_csv(raw_path)\ndf.head()\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df.info()\ndf.describe(include='all').T\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Cleaning (types, nulls, duplicates)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "df.columns = (df.columns.str.strip().str.lower().str.replace(' ', '_'))\ndf = df.drop_duplicates()\nnulls = df.isna().sum().sort_values(ascending=False)\nnulls  # inspect\n# Example: parse dates if present\n# df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Cohort Construction (first-watch month)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# If you have user-level events with 'user_id' & 'watch_date', build cohorts.\n# events = pd.read_csv('data/processed/view_events.csv')\n# events['watch_date'] = pd.to_datetime(events['watch_date'])\n# events['cohort_month'] = events.groupby('user_id')['watch_date'].transform(lambda s: s.min().to_period('M').to_timestamp())\n# retention = (events.assign(activity_month=lambda d: d['watch_date'].dt.to_period('M').dt.to_timestamp())\n#                    .groupby(['cohort_month','activity_month'])['user_id'].nunique()\n#                    .reset_index(name='active_users'))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Retention Heatmap\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# If 'retention' exists and cohort sizes computed:\n# cohort_sizes = retention.groupby('cohort_month')['active_users'].first().rename('cohort_size')\n# retention = retention.merge(cohort_sizes, on='cohort_month')\n# retention['retention_rate'] = retention['active_users'] / retention['cohort_size']\n# pivot = retention.pivot_table(index='cohort_month', columns='activity_month', values='retention_rate')\n# plt.figure(figsize=(10,6)); sns.heatmap(pivot, annot=False); plt.title('Cohort Retention Heatmap'); plt.tight_layout(); plt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Content Mix Trends (genre/time)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Example if df has 'listed_in' genres and 'date_added':\n# df['year'] = pd.to_datetime(df['date_added'], errors='coerce').dt.year\n# df['listed_in'] = df['listed_in'].str.split(', ')\n# genre_year = df.explode('listed_in').groupby(['year','listed_in']).size().reset_index(name='count')\n# # TODO: plot top genres over years\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Country Segmentation (top 10)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# country_counts = df.assign(country=df['country'].str.split(', ')).explode('country').country.value_counts().head(10)\n# country_counts.plot(kind='bar'); plt.title('Top 10 Countries by Titles'); plt.tight_layout(); plt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Simple Churn Baseline (train/test + metrics)\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# from sklearn.model_selection import train_test_split\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.metrics import classification_report, roc_auc_score\n# # X = user_features; y = churned\n# # X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n# # model = LogisticRegression(max_iter=1000).fit(X_train,y_train)\n# # preds = model.predict(X_test); probs = model.predict_proba(X_test)[:,1]\n# # print(classification_report(y_test,preds)); print('ROC AUC:', roc_auc_score(y_test, probs))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 9. Insights (5 bullets)\n- [ ] Retention takeaway #1\n- [ ] Content mix insight #2\n- [ ] Country segmentation insight #3\n- [ ] Model/metric observation #4\n- [ ] Business recommendation #5\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 10. Limits & Next Steps\n- Data limitations / assumptions\n- What to collect next\n- How to improve segmentation or churn modeling\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}